{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436b5410-c277-4c87-aee8-83dda0ec8ce4",
   "metadata": {},
   "source": [
    "## DS 6600: Data Engineering 1\n",
    "### Lab assignment 1\n",
    "Instructions: use a Jupyter notebook to complete the following questions. Use a markdown cell for text and a code cell for Python code. Once your notebook is complete, follow [these instructions](https://docs.google.com/document/d/1NhTn8j4dqDpvC77x-eIJpzNpLhkeAZQ4V9wvJiD94yc/edit?usp=sharing) to save the notebook as a PDF file and submit your assignment to Gradescope on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de10d5b2-9656-4d33-b713-98203249dd91",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "We are going to use Git and GitHub for this lab assignment. Please complete all of the following steps: \n",
    "\n",
    "* Create a new GitHub repository for this lab assignment called \"DS6600_lab1\". Make it public, add a README.md file, choose a .gitignore file that is specific to Python-based projects. Also, choose a licence (using [choosealicense.com](https://choosealicense.com/)) that allows other people to use the code in your repository for both commercial and non-commercial use, including full rights to distribute and modify the code, but does not allow anyone to modify and distribute your code with a more restrictive license than the one included in your repository. \n",
    "\n",
    "* In your terminal, choose a location on your computer for the local copy of this repository and use `git clone` to download it and connect this local directory to the GitHub repository. \n",
    "\n",
    "* In your README.md file, explain (in your own words! Copy-and-pasted answers will receive no credit) why you chose the license you did and what would have happened had you not supplied a license. In addition, examine your .gitignore file to confirm that a file named \".env\" will not be pushed to GitHub. Copy and paste the relevant section of the .gitignore file in your README.md file. \n",
    "\n",
    "* As you work on this assignment, add, commit, and push your changes to GitHub. We will look at your repository's commit history to make sure there are at least 6 commits (one for each of the questions on this lab). \n",
    "\n",
    "For this question on your assignment, all you need to supply in this notebook is a URL for your GitHub repository. Please type it here. [8 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b0d47",
   "metadata": {},
   "source": [
    "Github repository URL:\n",
    "\n",
    "https://github.com/stephanie-morrall/DS6600_lab1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f81305-5fb9-4284-96b2-18efba01bc9b",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Describe, in words, whether a virtual machine, a container, a virtual environment, or the global environment of a single computer is best suited for each of the following situations. Be clear about why the option you choose works best, and also about why the other options are insufficient or are overkill.\n",
    "\n",
    "### Part a\n",
    "The local chapter of [Meals on Wheels](https://www.cvillemeals.org/) worked with some UVA computer science students and volunteers from [WillowTree Apps](https://www.willowtreeapps.com/), who built them a [web portal for volunteers](https://www.cvillemeals.org/portal) to sign up for shifts and a [mobile app](https://apps.apple.com/us/app/meals-on-wheels-ca/id1620046443) that shows volunteers their driving routes with GPS mapping. The portal and app have been extremely useful for the local Meals on Wheels chapter, but unfortunately, the portal and app were built only for the Charlottesville chapter and is not usable by any other Meals on Wheels chapter at present. You've been asked to help every other Meals on Wheels chapter to benefit from these products by generalizing the code, and then making it available for free to any chapter that wants to use the portal and app. Every chapter has their own database of volunteers and clients, necessitating a large amount of storage that must also be accessible through an internet connection. [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175e82a-1c14-437c-a5c2-2c376bbe35f2",
   "metadata": {},
   "source": [
    "### Part b\n",
    "The [Legal Aid Justice Center](https://www.justice4all.org/), a Charlottesville-based legal aid nonprofit that advocates for the rights of immigrants and the working poor, has used a Freedom of Information Act request to get Virginia's Department of Labor and Industry (DOLI) to share their data on all [official complaints of wage theft](https://www.doli.virginia.gov/wp-content/uploads/2022/02/2022-Updated-POW-Claim-Form-and-Instructions-English.pdf) in Virginia over the last five years. The DOLI stored this data in an Excel file with horrible formatting: the column headers are given vague names, text has misspelling throughout the file (you see locations such as \"Rochmond\" and \"Norflok\"), data types are inconsistent within columns (sometimes a `$` is included with the wage amounts, sometimes `$` is excluded), and so on. They've asked you to clean the data and generate a report that lists the average claim of wage theft and a frequency table of the number of claims by locality. They don't need your code or data, just the report. [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76090b23-abde-4858-a3b7-3d98c19fa6c4",
   "metadata": {},
   "source": [
    "### Part c\n",
    "An international NGO called [Save the Children](https://www.savethechildren.org/) provides housing, food, medical care, and other assistance to individuals who have been displaced from their homes by conflict or natural disasters. But a major problem is that these displacement events can happen suddenly, without giving Save the Children any time to mobilize. Major migration events are more likely when the infrastructure and buildings in a city or town have been destroyed. Save the Children have asked you to build a predictive model that can detect from [land-satellite images](https://www.usgs.gov/landsat-missions/landsat-8) the extent of infrastructure damage in an area of interest and that can be deployed by several different individuals working for Save the Children. You build this model, but in addition to Python you require several open-source image processing software packages that only work on Ubuntu Linux. [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe23f2-f2e1-4385-b623-6b6292256f17",
   "metadata": {},
   "source": [
    "### Part d\n",
    "Sometime in the near future, Python announces the release of Python version 4. In this major update, all commands are now in Swedish, and any command written with English words such as \"read\" will now fail to run. You are willing to relearn Python in Swedish to use this much needed and long overdue upgrade, after all Python är ett programmeringsspråk som låter dig arbeta snabbt och integrera system mer effektivt. But you don't want the code you are writing for your current project in Python 3 to stop working once Python 4 is released. [6 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defe77a",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "One of the packages we will soon use is `ydata_profiling`, which creates an HTML dashboard from a dataframe for the purpose of exploratory data analysis. It remains one of the very best packages available for making an EDA dashboard, but the problem is this package [does not work with Python 3.13](https://github.com/ydataai/ydata-profiling/issues/1695):\n",
    "\n",
    "<img src=\"https://github.com/jkropko/DS-6001/raw/master/localimages/ydata313.png\" width='600'>\n",
    "\n",
    "Tough luck. If you are working in your global environment, now you have to reinstall an older version of Python on your machine and reinstall all of your packages again. There's a good chance that some of these reinstalls will generate more version incompatibility problems. And then you are stuck in a software version purgatory. When you get your system working again, if you can, it's fragile and may buckle and break with any additional new package. That's not a good place to be.\n",
    "\n",
    "But you are working with virtual environments and dealing with obnoxious package version conflicts is one of the main reasons why virtual environments are so useful.\n",
    "\n",
    "### Part a\n",
    "Create a new Conda environment that runs Python 3.12, *not* 3.13. Refer to the [textbook's discussion of miniconda](https://jkropko.github.io/surfing-the-data-pipeline/docker.html#virtual-environments-using-miniconda) to help you with the code.  Give this environment a name that is different from the one we've been using for class up to this point, and activate the environment on the terminal's command line. Use `conda` to install these packages: `neo4j python-dotenv pandas numpy scipy scikit-learn requests prince ipykernel conda-forge::wquantiles`. (We'll use `neo4j` and `python-dotenv` later in this lab.) Then use `pip` to install `ydata_profiling` (because the package is not available via `conda`). Copy and paste your command-line code into a markdown cell in your notebook.\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff622844",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Connect your notebook to this virtual environment as the kernel, and run the following code cell. If you are successful, it will run without error. (You may be prompted to \"Upgrade to ydata-sdk\". That's the paid version of the `ydata_profiling` package. My rule of thumb is not to pay for anything that can't be bothered to update itself to work on Python 3.13.)\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weighted # this is a module of wquantiles\n",
    "from scipy import stats\n",
    "import prince\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5fc06-68bf-4a93-b342-f2c85526960b",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "The [official Python images](https://hub.docker.com/_/python) on Docker Hub use a version of Linux called Debian. However, sometimes you might need to install additional software in a container other than Python and Python packages, and a lot of open source software only works on another version of Linux called Ubuntu.\n",
    "\n",
    "### Part a\n",
    "Write a Dockerfile that builds an image from the `ubuntu:latest` image on Docker Hub. Run the following Linux commands to install Python 3 onto Ubuntu: `apt-get update` and `apt-get install -y python3`. Once Python is installed, run the following command to launch Python from the command line: `python3`. Copy and paste the Dockerfile here. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6d959e-26a2-432b-ac74-f82bcbd95af3",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Prove that the Dockerfile is written correctly by building the image associated with this Dockerfile. Once you are able to build the image successfully, copy and paste the output of the build in your terminal here. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7652b4-5128-4408-812e-ec72d68176a8",
   "metadata": {},
   "source": [
    "### Part c\n",
    "We've mostly run Docker containers by using the `-p` tag to map the operations of a container to a port on our local machine. But another way to run a container is in \"interactive mode\" using the `-it` tag, which immediately replaces your command line with the command line that exists inside the container. If you've correctly specified your Dockerfile to both install and launch Python inside the container, running this container in interactive mode should result in showing you a Python command line. Type `docker run -it` followed by the name of the image you created in parts (a) and (b). Confirm that the Python prompt appears. Then copy-and-paste the output from your terminal from the `docker run` command here. [4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d361d87-5e15-44c9-8079-7b01a5ddaca4",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "Docker is for more than databases and Python. It can be used to deploy any kind of software on any operating system. For example, [NetHack](https://en.wikipedia.org/wiki/NetHack) is a classic text-based adventure video game. It was first released in the 1980s.\n",
    "\n",
    "Search on Docker Hub for NetHack. Find the Docker image for running NetHack that was posted by the user \"matsuu\". Then find a way to run a container on your computer from this image. If you are successful, then after answering the first few questions you will receive a passage from a sacred book, scroll, or text. Copy the passage and paste it here. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af269d-343c-4da0-a722-384fc06b80ce",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "We've discussed connecting to MySQL, PostgreSQL, and Mongo using Docker, but there are many different kinds of database systems for different situations, and as a data scientist who can hang with the data engineers, you will need to be able to set up a database from a system you haven't used before. For this problem, use your Docker skills and your navigation of available documentation to create a local Python connection to a graph database running on [Neo4j](https://neo4j.com/). See this [AWS blog[(https://aws.amazon.com/compare/the-difference-between-graph-and-relational-database/)] or the [textbook](https://jkropko.github.io/surfing-the-data-pipeline/ch6.html#graph-databases) for a deeper discussion of graph databases. \n",
    "\n",
    "### Part a\n",
    "Make sure the conda environment you created in problem 3 is selected as the kernel for this notebook, then run the following import statements. [4 points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4aa0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5a430",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the documentation listed on the [Docker Hub page for the official Neo4j Docker image](https://hub.docker.com/_/neo4j), and the Neo4j documentation linked there, to determine:\n",
    "\n",
    "* the default port the image runs on (there are two in this case, one called \"bolt\" is used for connecting to the database itself, and the other is used for an HTML dashboard with a user interface for working with the dashboard if you want to use a UI), \n",
    "\n",
    "* the folder inside the container that stores the data (feel free to ignore examples of folders outside the container as we can use `volumes` to manage that), \n",
    "\n",
    "* and the environmental variables required by the Neo4j image. Make sure you specify a password, and don't disable authentication with `--env=NEO4J_AUTH=none`. (You will need to use the Neo4j documentation outside of Docker Hub. Take a look at the \"Getting started with Neo4j in Docker\" page.)\n",
    "\n",
    "List your answers, and how/where you found those answers. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4929c89",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Create a compose.yaml file that launches a Neo4j container from the Neo4j official image on Docker Hub. In the compose.yaml file: attach the ports that are needed, load the necessary environmental variables via a .env file, and create a local volume named \"neo4jdata\" and map it to the data directory inside the container. Copy and paste your compose.yaml code into a Markdown cell in this notebook. [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8a6b9",
   "metadata": {},
   "source": [
    "### Part d\n",
    "Type `docker compose up` on the command line to launch the Neo4j container. Then run the following Python code. If your container is launched, the following code will display the phrase \"Connection to Neo4j established successfully\", you've succeeded in getting Neo4j to run on your system, and you are a rockstar data engineer. [8 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa83de-67ab-435c-8073-c68190eb5941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "NEO4J_AUTH = os.getenv('NEO4J_AUTH').split(\"/\")\n",
    "\n",
    "URI = \"bolt://localhost:7687\"\n",
    "USERNAME = NEO4J_AUTH[0]\n",
    "PASSWORD = NEO4J_AUTH[1]\n",
    "\n",
    "try:\n",
    "    # Create a Driver instance\n",
    "    # This only provides connection information, it does not establish a connection yet.\n",
    "    driver = GraphDatabase.driver(URI, auth=(USERNAME, PASSWORD))\n",
    "\n",
    "    # Verify connectivity immediately\n",
    "    # This forces the driver to create a connection and check credentials/compatibility.\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Connection to Neo4j established successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Neo4j: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the driver to release resources\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
